{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m3PAEPRDRLA3"
   },
   "source": [
    "# Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Error Function Formula: $\\frac{1}{2} \\|w\\|^2 + C\\displaystyle\\sum_{i=1}^{m}(\\xi_i + \\xi_i^*)$ -> $min$  \n",
    "1. Instead of only regression line, we will have a regression line with a tube has width equals $\\varepsilon$ measures by vertically (_y-axis_) on **above** and **below** regression line. this called $\\varepsilon$-$\\text{Insensitive Tube}$\n",
    "2. All the points fall inside the tube will be disregarding the error\n",
    "3. the point outside the tube will be **_measured distance with the tube_**. they (**Slack Variables**) are named as $\\xi_i$ if the point aboves the tube or $\\xi_i^*$ if the point belows the tube.\n",
    "4. $\\xi$ and $\\xi^*$ are used as a vector that supports building the model, => support vector regression  \n",
    "\n",
    "Ref: [Chapter 4 - Support Vector Regression](https://core.ac.uk/download/pdf/81523322.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0VCUAVIjRdzZ"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fXVXoFWtSF4_"
   },
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Position_Salaries.csv')\n",
    "X = dataset.iloc[:, 1:-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "y = y.reshape(len(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  45000]\n",
      " [  50000]\n",
      " [  60000]\n",
      " [  80000]\n",
      " [ 110000]\n",
      " [ 150000]\n",
      " [ 200000]\n",
      " [ 300000]\n",
      " [ 500000]\n",
      " [1000000]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YS8FeLHYS-nI"
   },
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Feature scaling should apply when using implicit equation model  \n",
    "> Feature scaling should apply both features and dependent variable if in numberic with high value (not apply to binary value and dummy varible)  \n",
    "> Feature scaling should apply after split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X = sc_X.fit_transform(X)\n",
    "y = sc_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.5666989 ]\n",
      " [-1.21854359]\n",
      " [-0.87038828]\n",
      " [-0.52223297]\n",
      " [-0.17407766]\n",
      " [ 0.17407766]\n",
      " [ 0.52223297]\n",
      " [ 0.87038828]\n",
      " [ 1.21854359]\n",
      " [ 1.5666989 ]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.72004253]\n",
      " [-0.70243757]\n",
      " [-0.66722767]\n",
      " [-0.59680786]\n",
      " [-0.49117815]\n",
      " [-0.35033854]\n",
      " [-0.17428902]\n",
      " [ 0.17781001]\n",
      " [ 0.88200808]\n",
      " [ 2.64250325]]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eiU6D2QFRjxY"
   },
   "source": [
    "## Training the SVR model on the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "deDnDr8UR5vq"
   },
   "source": [
    "## Predicting a new result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zzedFlUISSu_"
   },
   "source": [
    "## Visualising the SVR results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UahPVNlJSZ-K"
   },
   "source": [
    "## Visualising the SVR results (for higher resolution and smoother curve)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMnOMrgA1ePf/SG4K4vUFQy",
   "collapsed_sections": [],
   "name": "support_vector_regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
